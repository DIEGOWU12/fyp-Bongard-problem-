import requests
from bs4 import BeautifulSoup
import time
import random
import os
import csv
from urllib.parse import urljoin # ç”¨äºæ‹¼æ¥ç›¸å¯¹URL
# ====================================================================

# ====================================================================
# 1. è®¾ç½®ç›®æ ‡å’Œå‚æ•°
# ====================================================================
BASE_URL = "https://oebp.org/BP"
START_ID = 301  # ç›®æ ‡çˆ¬å– BP301 åˆ° BP600
END_ID = 1000  # ç›®æ ‡çˆ¬å– BP301 åˆ° BP1000
OUTPUT_DIR = "Bongard_Dataset_v2"
SOLUTION_FILE = os.path.join(OUTPUT_DIR, "solutions_and_images.csv")

# 2. åˆ›å»ºè¾“å‡ºç›®å½•
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"åˆ›å»ºç›®å½•: {OUTPUT_DIR}")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# ====================================================================
# æ–°å¢ï¼šTXT æ–‡ä»¶ä¿å­˜å‡½æ•°
# ====================================================================
def save_solution_to_txt(bp_id, solution_text):
    """å°†è§£å†³æ–¹æ¡ˆæ–‡æœ¬ä¿å­˜åˆ° BPID å¯¹åº”çš„å­æ–‡ä»¶å¤¹ä¸­"""
    bp_dir = os.path.join(OUTPUT_DIR, f"BP{bp_id}")
    if not os.path.exists(bp_dir):
        os.makedirs(bp_dir)
        
    txt_path = os.path.join(bp_dir, "solution.txt")
    
    try:
        # ä»¥ utf-8 ç¼–ç å†™å…¥æ–‡æœ¬æ–‡ä»¶
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(solution_text)
        # è¿”å›ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºCSVä¸­çš„è®°å½•ï¼ˆå¯é€‰ï¼‰
        return os.path.join(f"BP{bp_id}", "solution.txt")
    except Exception as e:
        print(f"å†™å…¥ BP{bp_id} çš„ TXT æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return "TXT å†™å…¥å¤±è´¥"


# ====================================================================
# ä¸‹è½½å‡½æ•° (ä¿æŒä¸å˜)
# ====================================================================
def download_and_save_image(img_url, filename, bp_id):
    """ä¸‹è½½å•ä¸ªå›¾ç‰‡å¹¶ä¿å­˜åˆ°å­ç›®å½•"""
    # ç¡®ä¿ä¿å­˜åˆ° BPID å¯¹åº”çš„å­æ–‡ä»¶å¤¹
    bp_dir = os.path.join(OUTPUT_DIR, f"BP{bp_id}")
    if not os.path.exists(bp_dir):
        os.makedirs(bp_dir)
        
    image_path = os.path.join(bp_dir, filename)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤ä¸‹è½½ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰
    if os.path.exists(image_path):
         return os.path.join(f"BP{bp_id}", filename)

    try:
        img_response = requests.get(img_url, headers=HEADERS, timeout=10)
        if img_response.status_code == 200:
            with open(image_path, 'wb') as f:
                f.write(img_response.content)
            return os.path.join(f"BP{bp_id}", filename) # è¿”å›ç›¸å¯¹è·¯å¾„ for CSV
        else:
            return f"ä¸‹è½½å¤±è´¥ (çŠ¶æ€ç : {img_response.status_code})"
    except Exception as e:
        return f"ä¸‹è½½å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}"

# ====================================================================
# æ ¸å¿ƒæ•°æ®æŠ“å–å‡½æ•° (è§£å†³æ–¹æ¡ˆå®šä½å·²ä¼˜åŒ–)
# ====================================================================
def fetch_bongard_problem(bp_id):
    """æ ¹æ® ID çˆ¬å–å•ä¸ª Bongard Problem çš„æ•°æ®"""
    url = f"{BASE_URL}{bp_id}"
    print(f"æ­£åœ¨å¤„ç†: {url}")

    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        
        if response.status_code == 404:
             print(f"è­¦å‘Š: BP{bp_id} é¡µé¢ä¸å­˜åœ¨ (404 Not Found)ã€‚è·³è¿‡ã€‚")
             return None
        elif response.status_code != 200:
            print(f"é”™è¯¯: è®¿é—® {url} å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None

        soup = BeautifulSoup(response.text, 'html.parser')

        data = {'BP_ID': f"BP{bp_id}", 'solution': 'æœªæ‰¾åˆ°è§£å†³æ–¹æ¡ˆæ–‡æœ¬', 'image_paths': [], 'txt_path': ''}

        # 3. æå–è§£å†³æ–¹æ¡ˆæ–‡æœ¬
        solution_text = "æœªæ‰¾åˆ°è§£å†³æ–¹æ¡ˆæ–‡æœ¬"
        bp_link_tag = soup.find('a', href=f'/{data["BP_ID"]}', string=data["BP_ID"])

        if bp_link_tag:
            solution_tr_inner = bp_link_tag.find_parent('tr')
            if solution_tr_inner:
                td_list = solution_tr_inner.find_all('td')
                if len(td_list) >= 3:
                    solution_text = td_list[2].get_text(strip=True)

        data['solution'] = solution_text
        data['txt_path'] = save_solution_to_txt(bp_id, solution_text)

        # 4. æå–å›¾ç‰‡
        img_tags = soup.find_all('img', src=lambda src: src and '/examples/' in src)

        # ğŸ”¥ æ–°å¢ï¼šç­›é€‰æ¡ä»¶ â€”â€” åªè¦ 12 å¼ å›¾çš„ BP
        if len(img_tags) != 12:
            print(f"BP{bp_id} å›¾ç‰‡æ•°é‡ = {len(img_tags)}ï¼ˆâ‰  12ï¼‰ï¼Œè·³è¿‡ã€‚")
            return None

        # ä¸‹è½½ 12 å¼ å›¾
        image_paths = []
        for img_tag in img_tags:
            img_src = img_tag['src']
            img_url = urljoin("https://oebp.org", img_src)
            filename = os.path.basename(img_src)
            path = download_and_save_image(img_url, filename, bp_id)
            image_paths.append(path)

        data['image_paths'] = image_paths

        return data

    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚ {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


# ====================================================================
# 5. ä¸»çˆ¬å–å¾ªç¯å’Œæ•°æ®ä¿å­˜
# ====================================================================
# åˆ›å»º CSV æ–‡ä»¶å¹¶å†™å…¥æ ‡é¢˜
# CSV å­—æ®µä¸­æ–°å¢ 'solution_txt_path' å­—æ®µ
with open(SOLUTION_FILE, 'w', newline='', encoding='utf-8') as f:
    fieldnames = ['BP_ID', 'solution', 'solution_txt_path'] + [f'Image_{i+1}_path' for i in range(12)]
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()

    for i in range(START_ID, END_ID + 1):
        try:
            result = fetch_bongard_problem(i)
        except Exception as e:
            print(f"å¤„ç† BP{i} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}. è·³è¿‡.")
            result = None

        if result:
            # å‡†å¤‡è¦å†™å…¥ CSV çš„å­—å…¸è¡Œ
            row = {
                'BP_ID': result['BP_ID'], 
                'solution': result['solution'], 
                'solution_txt_path': result['txt_path']
            }
            
            # å¡«å……å›¾ç‰‡è·¯å¾„
            for j in range(12):
                row[f'Image_{j+1}_path'] = result['image_paths'][j] if j < len(result['image_paths']) else ''

            writer.writerow(row)
            
            print("--- çˆ¬å–æˆåŠŸ ---")
            print(f"BP{i} æè¿°: {result['solution']}")
            print(f"BP{i} TXT æ–‡ä»¶å·²ä¿å­˜åˆ°: {result['txt_path']}")
            print(f"BP{i} å·²ä¸‹è½½ {len(result['image_paths'])} å¼ å›¾ç‰‡åˆ° {os.path.join(OUTPUT_DIR, f'BP{i}')}/")
            print("----------------\n")
            
        # 6. è®¾ç½®çˆ¬å–å»¶è¿Ÿ
        sleep_time = random.uniform(3, 7) # éšæœºç­‰å¾… 3 åˆ° 7 ç§’
        time.sleep(sleep_time)

print(f"æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚æ•°æ®ä¿å­˜åœ¨ {SOLUTION_FILE}ï¼Œå›¾ç‰‡å’Œ TXT æ–‡ä»¶æŒ‰ BPID åˆ†æ–‡ä»¶å¤¹ä¿å­˜åœ¨ {OUTPUT_DIR}/")